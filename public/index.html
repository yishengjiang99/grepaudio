<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="ie=edge">
  <title>rt</title>
  <link rel="stylesheet" href="style.css">
  <link rel="stylesheet" href="./simple-console.css">
  <script src="./simple-console.js"></script>
  <script src="https://www.gstatic.com/firebasejs/7.14.2/firebase-app.js"></script>
  <script src="https://www.gstatic.com/firebasejs/7.14.2/firebase-database.js"></script>
  <script src="https://www.gstatic.com/firebasejs/7.14.2/firebase-auth.js"></script>

</head>

<body onclick="void(0);">
  <div id="overlay" title="Click to turn off the overlay effect" style="display: block;">
    <div class="text"><br>
      <br><span style="font-size:20px;" class="w3-black w3-padding w3-hide-medium w3-hide-small">
       GrepAwk Audio
       
      </span>
      <button class='button' style='font-size:20px'> Start Audio Context. </button>
    </div>
  </div>
  <h3>Mix Sounds </h3>

  <div style='height:30%' id="eq_update_form">
    <canvas id='band_freq_out' style='position:absolute;right:10px;top:1px'></canvas>
  </div>


  <br>
  <div style='position:relative'>
    <span style='width:350px;'>
      <label for="search">Search</label>
      <input type=text id='ytsearch' placeholder='search youtube' size=30 data-host='/api/sudo/::QUERY::.mp3' />
      <div id=ctrls>
      </div>
      <div>
        <button id="recorder">Start Recording</button>
        <audio id='audio2'></audio>

      </div>
    </span>
    <span style='width:40%;position:absolute; top:0;left:350px'>
      <div class='canvas_wrapper'>
        <div> <input id='showfft' type=checkbox checked>fft</input>
          <input id='showcummulative' type=checkbox>cumulative fft</input>
          <input id='showtimeseries' type=checkbox checked>timeseries</input>
          <button id='zoomin'>+</button> <button id='zoomout'>-</button></div>
        <canvas id='output_freq'></canvas>

        <canvas id='output_timeline'></canvas>
    <span id="rx1"></span>
    <span id='rx0'></span>
      </div>

    </span>
    <span style='position:absolute; bottom:100px;right:320px'>
      <button id=obs>Broadcast</button>
     <object src="https://www.youtube.com/embed/PgGC3r24fBg?controls=0" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></object>
      <form id='noisegate'>
        Noise Gate:
        <div class="range-wrap">
          <output id=threshold_l>Gate: </output><output class="bubble"></output>

          <input aria-labelledby='threshold_l' type="range" min='-100' max='0' value='-80' class="range"
            name='threshold'>
        </div>
      </form>
      <audio controls="controls" id='audio1' src='./samples/song.mp3'></audio>

    </span>
  </div>

  <div id='serverlist'></div>


  <input type='file' id='file'>

  <script>
    var blob = window.URL || window.webkitURL;

    document.getElementById('file').addEventListener('change', function (event) {
      var file = this.files[0];
      var fileURL = blob.createObjectURL(file);
      $("#audio2").src = fileURL;
      $("#audio2").autoplay = true;
    });
  </script>

  <script src='polyfills.js'></script>


  <div id=console></div>

  <div id='rx2log'></div>


  <script type='module'>
    import equilizer from "./equalizer.js";
    import Mixer from './Mixer.js';
    import NoiseGate from './NoiseGate/NoiseGate.js'
    import { split_band } from './splitband.js'
    import AnalyzerView from "./AnalyzerView.js"
    import BandPassFilterNode from './band_pass_lfc/BandPassFilterNode.js'
    import {broadcast} from './twitch_audio.js'

    let audioCtx, audioTag, eq;
    // const list = $("#serverlist")
    // fetch("/api/list").then(resp => resp.json()).then(json => {
    //   json.forEach(section => {
    //     list.appendstr(`<h4>${section.name}</h4>`);
    //     section.list.forEach(li => {
    //       list.appendstr(`<li>List1</li>`)
    //     })
    //   })
    // })


    $("#overlay").onclick = async function (e) {
      $("#overlay").style.zIndex = -99;

      this.style.display = 'none';

      audioCtx = new AudioContext();
      await audioCtx.audioWorklet.addModule('../band_pass_lfc/processor.js');

      window.g_audioCtx = audioCtx;

      var audioTag = await Mixer(audioCtx, "ctrls");

      audioTag.add_audio_tag("audio1", 5);

      window.g_audioTag = audioTag;
      var noiseGate = new NoiseGate(audioCtx);
      noiseGate.port.postMessage("ping");
      noiseGate.port.onmessage = (evt) => {
        log(JSON.stringify(evt.data));
      }
      audioTag.outputNode.connect(noiseGate.input);
      var bandpassFilterNode = await new BandPassFilterNode(audioCtx);
      noiseGate.output.connect(bandpassFilterNode);



      var cursor = bandpassFilterNode;

      var compressor = new DynamicsCompressorNode(audioCtx, {threshold:-10, ratio:20,knee:10});

      var group = split_band(audioCtx, [31.25, 62.5, 125, 250, 500, 1000, 2000, 4000, 8000, 16000]);
      bandpassFilterNode.connect(compressor).connect(group.input);


      $("#eq_update_form").appendChild(group.UI_EQ(bandpassFilterNode,compressor));
      $("#obs").onclick=function(e){
        broadcast(audioCtx, 'yisheng');
      }
      cursor = group.output;
      var ctv = AnalyzerView(cursor, { fft: 256 });
      ctv.histogram("output_freq", 700, 300); //, { fft: 256 })
      ctv.timeseries("output_timeline", 128, 700, 300); //, { fft: 256 })
        histogram2('band_freq_out', av);

      var rworker = new Worker('recorder-worker.js');
      var rconfig = { sample: 2 << 16, channels: 1 };
      rworker.postMessage({
        command: 'init',
        config: {
          sampleRate: audioCtx.sampleRate,
          numChannels: 2,
        }
      });

      rworker.onmessage = (e) => {
        if (e.data.audioUrl) {
          log(" got url " + e.data.audioUrl)
          $("#audio2").src = e.data.audioUrl;
          $("#audio2").controls = true;
          $("#audio2").parentElement.appendstr(`<a href='${e.data.audioUrl}'>${e.data.audioUrl}</a>`)
        }
        console.log(e);
      };


      var recorderProcessor = audioCtx.createScriptProcessor(1024, 2, 2);

      recorderProcessor.onaudioprocess = (e) => {

        // The input buffer is the song we loaded earlier
        var inputBuffer = e.inputBuffer;

        // The output buffer contains the samples that will be modified and played
        var outputBuffer = e.outputBuffer;
        var buffer = [];
        for (var channel = 0; channel < outputBuffer.numberOfChannels; channel++) {
          var inputData = inputBuffer.getChannelData(channel);
          var outputData = outputBuffer.getChannelData(channel);
          if (isRecording) buffer.push(inputData);

          // Loop through the 4096 samples
          for (var sample = 0; sample < inputBuffer.length; sample++) {
            // make output equal to the same as the input
            outputData[sample] = inputData[sample];
          }
        }
        if (!isRecording) return;
        rworker.postMessage({
          command: 'record',
          buffer: buffer
        });
      };

      ctv.analyzer.connect(recorderProcessor);
      recorderProcessor.connect(audioCtx.destination);
      var isRecording = false;
      var chunks = [];
      $("#recorder").onclick = function (e) {
        if (isRecording == false) {
          isRecording = true;
          e.target.innerText = 'Done'
        } else {
          isRecording = false;
          e.target.innerText = 'record'
          rworker.postMessage({
            command: "exportWAV"
          })
        }
      }
      window.vfs = [group, audioTag, noiseGate, bandpassFilterNode, audioCtx, group];

      window.index_stdin = function (str) {
        const cmd = str.split(" ")[0];
        const arg1 = str.split(" ")[1] || "";
        const arg2 = str.split(" ")[2] || "";
        switch (cmd) {
          case 'debug':
            switch (arg1) {
              case 'group': group.aggregate_fr(); break;
              default: break;
            }
          case "ls":
            return JSON.stringify(window.g_audioTag)
            break;
          case 'fullscreen':
          case 'terminal':
          case 'term':
            $("#app1").style.display = 'none';
            con.element.style.height = '100vh';
            return true;
          case "ls":
            var str = window.vfs.map(obj => objs.toString()).forEach(str => log(str));
            log(str);
            return true;
          case 'v':
          case 'video':
              
            g_audioTag.loadURLTo("/api"+arg1+".mp3",1);
            break;
          default: return false;
        }
      }

      if (location.hash) {
        window.index_stdin(location.hash)
      }

      con.element.style.zIndex = 99;
      con.element.addEventListener("click", function () { this.querySelector("input").focus() });
      window.onkeydown = function (evt) {
        if (evt.code == "Enter") {
          con.element.querySelector("input").focus();
        }
      }
    }


  </script>

</body>

</html>
