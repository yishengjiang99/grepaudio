<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="ie=edge">
  <title>rt</title>
  <link rel="stylesheet" href="./style.css">
  <link rel="stylesheet" href="./led.css">
  <link rel="stylesheet" href="./simple-console.css">
  <script src="./simple-console.js"></script>
</head>
<body>

<div id='led-1' class='led-box'>
 <div class='led-green'></div>
</div>


<div>

  <input type=radio value='mic' name='media'>Record from mic</input>
  <input type=radio checked  value='output' name='media'>Record from stdout</input>
<div>
<div>
  <button style='display:block' id='rec'>record</button>
 <!-- <button style-'display:none' id='done'>Finish</button> -->
</div>


<canvas id=c1></canvas>
<canvas id=c2></canvas>
</div>
<audio controls id='tagg'></audio>
</body>
  <script src='./polyfills.js'></script>


  <script type='module'>
// import AnalyzerView from './AnalyzerView.js';
function Recorder(ctx){
  var ctx = ctx;
  var state = "init";

  var chunks = [];
  var decodedChunks = [];
  var destination = ctx.createMediaStreamDestination();

  function test(){
    try{
      var osc = ctx.createOscillator();
      var gain = ctx.createGain();
      const now = ctx.currentTime;
      gain.gain.setValueAtTime(3,now+1);
      gain.gain.setValueAtTime(0,now+3);
      gain.gain.setValueAtTime(3,now+5);
      gain.gain.setValueAtTime(0,now+7);
      osc.connect(gain);
      gain.connect(ctx.destination);
      var r = Recorder(ctx);
      r.start();
      osc.start();
      setTimeout(r.stop, 5);
    }catch(e){
      log(e.message);
    }
  }

  return{
    recorder,
    test,stop,start,
    output:blob
  }
}

var ac = new AudioContext();
var b = document.querySelector("button");
var clicked = false;
var r;



b.addEventListener("click", function(e) {
  if (!clicked) {
    try{
      var connection = new WebSocket( 'wss://dsp.grepawk.com/stdin');
      connection.binaryType = "arraybuffer";
      connection.onopen = () => console.log("connection open");
      connection.onmessage = (m) => console.log(m);
      connection.onclose = () => console.log("close")
      connection.onerror = (e) => console.log(e);
      var ctx = new AudioContext();

      var osc = ctx.createOscillator();
      var gain = ctx.createGain();
      const now = ctx.currentTime;
      gain.gain.setValueAtTime(3,now+1);
      gain.gain.setValueAtTime(0,now+3);
      gain.gain.setValueAtTime(3,now+5);
      gain.gain.setValueAtTime(0,now+7);
      osc.connect(gain);

      var scriptNode = ctx.createScriptProcessor(4096, 1, 1);
      gain.connect(scriptNode);
      scriptNode.connect(ctx.destination);
      console.log(scriptNode.bufferSize);
      scriptNode.onaudioprocess = function(evt) {
            connection.send(evt.inputBuffer);
                    // The input buffer is the song we loaded earlier
            var inputBuffer = evt.inputBuffer;

            // The output buffer contains the samples that will be modified and played
            var outputBuffer = evt.outputBuffer;

            // Loop through the output channels (in this case there is only one)
            for (var channel = 0; channel < outputBuffer.numberOfChannels; channel++) {
              var inputData = inputBuffer.getChannelData(channel);
              var outputData = outputBuffer.getChannelData(channel);

              // Loop through the 4096 samples
              for (var sample = 0; sample < inputBuffer.length; sample++) {
                    outputData[sample] = inputData[sample];

              }
            }
      }


    osc.start();
      // setTimeout(r.stop, 5);
    }catch(e){
      log(e.message);
    }
  } else {
      r.stop();
      osc.stop();
connection.close();
      b.disabled=true;
      console.log(r.blob);
  }
});




  </script>
  </body>
